{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3VDN0rKNZFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/intelpro/Samsung_TAsession\n",
        "%cd /content/Samsung_TAsession/PSMnet/\n",
        "!ls\n",
        "!mkdir saved_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "datapath = '/content/gdrive/MyDrive/samsung_TAsession/KITTI_2015/training/'\n",
        "savemodel = './saved_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRTl7SsaNZFx",
        "colab_type": "text"
      },
      "source": [
        "## import module and function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhOSwtfNZFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.utils.data \n",
        "from torch.autograd import Variable \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from submodule import *\n",
        "from preprocess import *\n",
        "from dataloader import listflowfile as lt\n",
        "from dataloader.KITTILoader import *\n",
        "from dataloader.KITTIloader2015 import *"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcQsp0SNZF8",
        "colab_type": "text"
      },
      "source": [
        "## Get dataset string\n",
        "### Get strings such as left image, right image, and disparity in the data path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7afvyloJNZF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp = dataloader(datapath)\n",
        "print('left image string:', all_left_img[0])\n",
        "print('right image string: ', all_right_img[0])\n",
        "print('left disparity string: ', all_left_disp[0])\n",
        "print('test left image string: ',test_left_img[0])\n",
        "print('test right image string: ', test_right_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKy9vHUkNZF_",
        "colab_type": "text"
      },
      "source": [
        "## Define dataloader\n",
        "### Define dataloader using image string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE8AT1rdNZF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KITTI_dataset_train = myImageFloder(all_left_img,all_right_img,all_left_disp, True)\n",
        "TrainImgLoader = torch.utils.data.DataLoader(KITTI_dataset_train, \n",
        "      batch_size=1, shuffle= True, num_workers= 8, drop_last=False)\n",
        "print('Train object: ', TrainImgLoader)\n",
        "KITTI_dataset_test = myImageFloder(test_left_img, test_right_img, test_left_disp, True)\n",
        "TestImgLoader = torch.utils.data.DataLoader(KITTI_dataset_test, \\\n",
        "                batch_size=8, shuffle= False, num_workers= 4, drop_last=False)\n",
        "print('Test object: ', TestImgLoader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iATBEOIUNZGC",
        "colab_type": "text"
      },
      "source": [
        "## Check KITTI dataset data\n",
        "### Plot the images using the KITTI dataset information we defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNMI3KBXNZGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_img, right_img, left_disp = KITTI_dataset_train.__getitem__(0)\n",
        "plt.figure()\n",
        "plt.title('left image')\n",
        "plt.imshow(left_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "plt.figure()\n",
        "plt.title('right image')\n",
        "plt.imshow(right_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "plt.figure()\n",
        "plt.title('ground truth left disparity')\n",
        "plt.imshow(left_disp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrZ0754qNrUq",
        "colab_type": "text"
      },
      "source": [
        "## Define feature extractor \n",
        "### Let`s define a function to extract features from the image\n",
        "### Among them, we will implemet the Spatial pyramid pooling module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-eQvqBwN4XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convbn(in_planes, out_planes, kernel_size, stride, pad, dilation):\n",
        "    return nn.Sequential(nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation = dilation, bias=False), \\\n",
        "                         nn.BatchNorm2d(out_planes))\n",
        "\n",
        "class feature_extraction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(feature_extraction, self).__init__()\n",
        "        self.inplanes = 32\n",
        "        self.firstconv = nn.Sequential(convbn(3, 32, 3, 2, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, 32, 3, 1,1,1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 64, 16, 2,1,1) \n",
        "        self.layer3 = self._make_layer(BasicBlock, 128, 3, 1,1,1)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 128, 3, 1,1,2)\n",
        "\n",
        "        ## Your implementation Here - Spatial pyramid pooling module\n",
        "        self.branch1 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch2 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch3 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch4 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "        ## Your implementation end - Spatial pyramid pooling module   \n",
        "\n",
        "        self.lastconv = nn.Sequential(convbn(320, 128, 3, 1, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(128, 32, kernel_size=1, padding=0, stride = 1, bias=False))\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride, pad, dilation):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "           downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, pad, dilation))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,1,None,pad,dilation))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output      = self.firstconv(x)\n",
        "        output      = self.layer1(output)\n",
        "        output_raw  = self.layer2(output)\n",
        "        output      = self.layer3(output_raw)\n",
        "        output_skip = self.layer4(output)\n",
        "\n",
        "\n",
        "        output_branch1 = self.branch1(output_skip)\n",
        "        output_branch1 = F.upsample(output_branch1, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch2 = self.branch2(output_skip)\n",
        "        output_branch2 = F.upsample(output_branch2, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch3 = self.branch3(output_skip)\n",
        "        output_branch3 = F.upsample(output_branch3, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch4 = self.branch4(output_skip)\n",
        "        output_branch4 = F.upsample(output_branch4, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_feature = torch.cat((output_raw, output_skip, output_branch4, output_branch3, output_branch2, output_branch1), 1)\n",
        "        output_feature = self.lastconv(output_feature)\n",
        "\n",
        "        return output_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Define hourglass module\n",
        "### Let`s define hourglass module using 3d convolution and batchnormalization3D\n",
        "### Please refer to convbn_3d function"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convbn_3d(in_planes, out_planes, kernel_size, stride, pad):\n",
        "    return nn.Sequential(nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, padding=pad, stride=stride,bias=False),\n",
        "                         nn.BatchNorm3d(out_planes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class hourglass(nn.Module):\n",
        "    def __init__(self, inplanes):\n",
        "        super(hourglass, self).__init__()\n",
        "        ## Your implementation Here - Hourglass module\n",
        "        self.conv1 = NotImplemented\n",
        "        self.conv2 = NotImplemented\n",
        "        self.conv3 = NotImplemented\n",
        "        self.conv4 = NotImplemented\n",
        "        self.conv5 = NotImplemented\n",
        "        self.conv6 = NotImplemented\n",
        "        ## Your implementation end - Hourglass module\n",
        "\n",
        "    def forward(self, x, presqu, postsqu):\n",
        "        \n",
        "        out  = self.conv1(x) #in:1/4 out:1/8\n",
        "        pre  = self.conv2(out) #in:1/8 out:1/8\n",
        "        if postsqu is not None:\n",
        "           pre = F.relu(pre + postsqu, inplace=True)\n",
        "        else:\n",
        "           pre = F.relu(pre, inplace=True)\n",
        "\n",
        "        out  = self.conv3(pre) #in:1/8 out:1/16\n",
        "        out  = self.conv4(out) #in:1/16 out:1/16\n",
        "\n",
        "        if presqu is not None:\n",
        "           post = F.relu(self.conv5(out)+presqu, inplace=True) #in:1/16 out:1/8\n",
        "        else:\n",
        "           post = F.relu(self.conv5(out)+pre, inplace=True) \n",
        "\n",
        "        out  = self.conv6(post)  #in:1/8 out:1/4\n",
        "        return out, pre, post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEGL3J7eNZF0",
        "colab_type": "text"
      },
      "source": [
        "## PSMnet\n",
        "### Define PSMnet \n",
        "#### Step1: Define feature extraction part\n",
        "#### Step2: Defien 3D convolution part\n",
        "#### Step3: weight initialization \n",
        "### PSMnet forward\n",
        "#### Step1: In left, right image, feature extraction is performed\n",
        "#### Step2: make cost volume.\n",
        "#### Step3: cost volume refinement using 3D CNN. \n",
        "#### Step4: perform disparity regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VpDx9EXNZF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PSMNet(nn.Module):\n",
        "    def __init__(self, maxdisp):\n",
        "        super(PSMNet, self).__init__()\n",
        "        self.maxdisp = maxdisp\n",
        "        # step1 - feature extractor \n",
        "        self.feature_extraction = feature_extraction()\n",
        "        # step2 - 3D convolution part\n",
        "        self.dres0 = nn.Sequential(convbn_3d(64, 32, 3, 1, 1),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     convbn_3d(32, 32, 3, 1, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
        "\n",
        "        self.dres2 = hourglass(32)\n",
        "        self.dres3 = hourglass(32)\n",
        "        self.dres4 = hourglass(32)\n",
        "\n",
        "        self.classif1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "\n",
        "        self.classif2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "\n",
        "        self.classif3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "        \n",
        "        # Step3 - weight initialization \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.Conv3d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, left, right):\n",
        "        # Step 1 - feature extraction\n",
        "        refimg_fea     = self.feature_extraction(left)\n",
        "        targetimg_fea  = self.feature_extraction(right)\n",
        "\n",
        "\n",
        "        # Step 2: make cost volume.\n",
        "        cost = Variable(torch.FloatTensor(refimg_fea.size()[0], refimg_fea.size()[1]*2, self.maxdisp//4,  refimg_fea.size()[2],  refimg_fea.size()[3]).zero_()).cuda()\n",
        "\n",
        "        for i in range(self.maxdisp//4):\n",
        "            if i > 0 :\n",
        "             cost[:, :refimg_fea.size()[1], i, :,i:]   = refimg_fea[:,:,:,i:]\n",
        "             cost[:, refimg_fea.size()[1]:, i, :,i:] = targetimg_fea[:,:,:,:-i]\n",
        "            else:\n",
        "             cost[:, :refimg_fea.size()[1], i, :,:]   = refimg_fea\n",
        "             cost[:, refimg_fea.size()[1]:, i, :,:]   = targetimg_fea\n",
        "        cost = cost.contiguous()\n",
        "        # Step 3: Perform 3D convolution.\n",
        "        cost0 = self.dres0(cost)\n",
        "        cost0 = self.dres1(cost0) + cost0\n",
        "\n",
        "        out1, pre1, post1 = self.dres2(cost0, None, None) \n",
        "        out1 = out1+cost0\n",
        "\n",
        "        out2, pre2, post2 = self.dres3(out1, pre1, post1) \n",
        "        out2 = out2+cost0\n",
        "\n",
        "        out3, pre3, post3 = self.dres4(out2, pre1, post2) \n",
        "        out3 = out3+cost0\n",
        "\n",
        "        cost1 = self.classif1(out1)\n",
        "        cost2 = self.classif2(out2) + cost1\n",
        "        cost3 = self.classif3(out3) + cost2\n",
        "        if self.training:\n",
        "          cost1 = F.upsample(cost1, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "          cost2 = F.upsample(cost2, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "\n",
        "          cost1 = torch.squeeze(cost1,1)\n",
        "          pred1 = F.softmax(cost1,dim=1)\n",
        "          pred1 = disparityregression(self.maxdisp)(pred1)\n",
        "\n",
        "          cost2 = torch.squeeze(cost2,1)\n",
        "          pred2 = F.softmax(cost2,dim=1)\n",
        "          pred2 = disparityregression(self.maxdisp)(pred2)\n",
        "\n",
        "        cost3 = F.upsample(cost3, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "        cost3 = torch.squeeze(cost3,1)\n",
        "        pred3 = F.softmax(cost3,dim=1)\n",
        "        # Step 4: disparity regression. \n",
        "        pred3 = disparityregression(self.maxdisp)(pred3)\n",
        "\n",
        "        if self.training:\n",
        "            return pred1, pred2, pred3\n",
        "        else:\n",
        "            return pred3        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyqpsr0hNZF4",
        "colab_type": "text"
      },
      "source": [
        "## main function\n",
        "### Specify various hyperparmeters and dataset paths. \n",
        "### Define model. \n",
        "### Defien optimizer. \n",
        "### print model we can see all details of module. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "V4F1bslkNZF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    max_disp = 192\n",
        "    epochs = 1\n",
        "    model = PSMNet(max_disp)\n",
        "    model = model.cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "    print(model.feature_extraction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn99TTQXYGDK",
        "colab_type": "text"
      },
      "source": [
        "## Training with KITTI dataset\n",
        "### Perform training during 1 epoch. \n",
        "### As the loss function, smoothness L1 loss is used\n",
        "### see training log and the training loss normally decreases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3rJ-3m3NZGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for epoch in range(0, epochs):\n",
        "        total_train_loss = 0\n",
        "        print('This is %d-th epoch' %(epoch))\n",
        "        model.train()\n",
        "        #------------- Train ------------------------------------------------------------\n",
        "        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n",
        "            imgL_crop, imgR_crop, disp_crop_L = imgL_crop.cuda(), imgR_crop.cuda(), disp_crop_L.cuda()\n",
        "            mask = disp_crop_L < max_disp\n",
        "            mask.detach_()\n",
        "            start_time = time.time()\n",
        "            output = model(imgL_crop, imgR_crop)\n",
        "            loss = F.smooth_l1_loss(output[0][mask], disp_crop_L[mask], size_average=True)\n",
        "            loss.backward()\n",
        "            total_train_loss += loss.detach().item()\n",
        "            optimizer.step()\n",
        "            if batch_idx % 3 == 0:\n",
        "                print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
        "        print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
        "        #SAVE\n",
        "        savefilename = savemodel+'/checkpoint_'+str(epoch)+'.tar'\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'train_loss': total_train_loss/len(TrainImgLoader),\n",
        "         }, savefilename)\n",
        "        #------------- TEST ------------------------------------------------------------\n",
        "        total_test_loss = 0\n",
        "        for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n",
        "            test_loss, disp = test(model, imgL,imgR, disp_L)\n",
        "            print('Iter %d test loss = %.3f' %(batch_idx, test_loss))\n",
        "            total_test_loss += test_loss\n",
        "        print('total test loss = %.3f' %(total_test_loss/len(TestImgLoader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HkS7XCDZKm1",
        "colab_type": "text"
      },
      "source": [
        "## Test with KITTI test sample \n",
        "### Let`s print the disparity image using data from the test set.\n",
        "### Because training takes a long time, we use a pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAAm_ISLZwe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_image_path = '/content/gdrive/My Drive/RE510_exp/KITTI_2015/testing/left.png'\n",
        "right_image_path = '/content/gdrive/My Drive/RE510_exp/KITTI_2015/testing/right.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvoIWOdRZZyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def test_img(imgL,imgR):\n",
        "      model.eval()\n",
        "\n",
        "      imgL = imgL.cuda()\n",
        "      imgR = imgR.cuda()     \n",
        "\n",
        "      with torch.no_grad():\n",
        "          disp = model(imgL,imgR)\n",
        "\n",
        "      disp = torch.squeeze(disp)\n",
        "      pred_disp = disp.data.cpu().numpy()\n",
        "\n",
        "      return pred_disp\n",
        "if __name__=='__main__':\n",
        "    from collections import OrderedDict\n",
        "    checkpoint = torch.load('/content/gdrive/My Drive/RE510_exp/pretrained_model_KITTI2015.tar')\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in checkpoint['state_dict'].items():\n",
        "        name = k[7:]\n",
        "        new_state_dict[name] = v    \n",
        "    model.load_state_dict(new_state_dict)    \n",
        "    normal_mean_var = {'mean': [0.485, 0.456, 0.406],\n",
        "                        'std': [0.229, 0.224, 0.225]}\n",
        "    infer_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                          transforms.Normalize(**normal_mean_var)])    \n",
        "\n",
        "    imgL_o = Image.open(left_image_path).convert('RGB')\n",
        "    imgR_o = Image.open(right_image_path).convert('RGB')\n",
        "\n",
        "    imgL = infer_transform(imgL_o)\n",
        "    imgR = infer_transform(imgR_o) \n",
        "\n",
        "    # pad to width and hight to 16 times\n",
        "    if imgL.shape[1] % 16 != 0:\n",
        "        times = imgL.shape[1]//16       \n",
        "        top_pad = (times+1)*16 -imgL.shape[1]\n",
        "    else:\n",
        "        top_pad = 0\n",
        "\n",
        "    if imgL.shape[2] % 16 != 0:\n",
        "        times = imgL.shape[2]//16                       \n",
        "        right_pad = (times+1)*16-imgL.shape[2]\n",
        "    else:\n",
        "        right_pad = 0    \n",
        "\n",
        "    imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
        "    imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    pred_disp = test_img(imgL,imgR)\n",
        "    if top_pad !=0 or right_pad != 0:\n",
        "      img = pred_disp[top_pad:,:-right_pad]\n",
        "    else:\n",
        "      img = pred_disp\n",
        "    plt.figure()\n",
        "    plt.title('left image')\n",
        "    plt.imshow(imgL_o)\n",
        "    plt.figure()\n",
        "    plt.title('disparity output')\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    print('time = %.2f' %(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "PSMnet.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}